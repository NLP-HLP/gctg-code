{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f00fd80",
   "metadata": {},
   "source": [
    "# Gaze modeling\n",
    "\n",
    "This notebook demonstrates how to train a gaze model to predict token-level reading measures from text.\n",
    "\n",
    "Currently, there are two gaze model implementations:\n",
    "- a transformer-based model to be fine-tuned from a causal language model, and\n",
    "- a linear regression model using word length and frequency as features.\n",
    "\n",
    "Let's train one of each and evaluate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e02d12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from modeling import reading_measures\n",
    "from modeling.dataset import GazeTextDataset\n",
    "from modeling.gaze_models import CausalTransformerGazeModel, LinearRegressionGazeModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066d1999",
   "metadata": {},
   "source": [
    "## Loading and preprocessing the dataset\n",
    "\n",
    "We are using the EMTeC dataset (eye tracking while reading generated texts) and preprocessing it in the following way:\n",
    "\n",
    "1. Calculating the first-pass gaze duration for each word and participant.\n",
    "2. Clamping the gaze durations within $\\pm 3$ standard deviations of the mean.\n",
    "3. Averaging the gaze durations across participants for each word.\n",
    "\n",
    "Refer to [`dataset.py`](modeling/dataset.py) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f1c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_measure = reading_measures.first_pass_gaze_duration\n",
    "outlier_zscore = 3\n",
    "\n",
    "emtec = GazeTextDataset.load(\n",
    "    \"data/emtec\",\n",
    "    reading_measure,\n",
    "    outlier_zscore,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ba5847",
   "metadata": {},
   "source": [
    "Next, let's split the dataset into a training set (80%) and a development set (20%):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00505eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, dev_dataset = emtec.random_split(0.8)\n",
    "\n",
    "print(f\"Train: {len(train_dataset.texts)} texts, {len(train_dataset.gaze_data)} AOIs\")\n",
    "print(f\"Dev: {len(dev_dataset.texts)} texts, {len(dev_dataset.gaze_data)} AOIs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a1bcc",
   "metadata": {},
   "source": [
    "Finally, we're going to normalize the gaze durations to have mean 0 and standard deviation 1. This will make training easier, and it will also help us interpret the gaze scores in the text generation process later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692fb1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.normalize_gaze_labels()\n",
    "# Normalize dev_dataset based on the mean and std of train_dataset\n",
    "dev_dataset.normalize_gaze_labels(\n",
    "    train_dataset.gaze_label_mean, train_dataset.gaze_label_std\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ecc646",
   "metadata": {},
   "source": [
    "## Training a linear regression model\n",
    "\n",
    "This model predicts first-pass gaze duration for each word based on the length and frequency of the word itself, as well as the length and frequency of the previous 2 words to account for spillover effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128c1809",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gaze_model = LinearRegressionGazeModel(lang=\"en\", max_spillover=2)\n",
    "lr_gaze_model.fit(\n",
    "    train_dataset,\n",
    "    dev_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc654e5",
   "metadata": {},
   "source": [
    "The `predict()` method returns the sum of the gaze durations for all words. You can use `predict_aois()` to reconstruct the gaze durations for each word separately (this is necessary due to tokenization differences between the dataset and the gaze models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade02e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_example(gaze_model):\n",
    "    text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "    aoi_ends = [3, 9, 15, 19, 25, 30, 34, 39, 44]\n",
    "    total_pred = gaze_model.predict([text])[0]\n",
    "    aoi_preds = gaze_model.predict_aois(text, aoi_ends)\n",
    "    aoi_start = 0\n",
    "    for aoi_end, aoi_pred in zip(aoi_ends, aoi_preds):\n",
    "        word = text[aoi_start:aoi_end].strip()\n",
    "        print(f\"{word}\\t{aoi_pred:.3f}\")\n",
    "        aoi_start = aoi_end\n",
    "    print(f\"\\nTotal\\t{total_pred:.3f}\")\n",
    "\n",
    "predict_example(lr_gaze_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfea868e",
   "metadata": {},
   "source": [
    "## Training a transformer model\n",
    "\n",
    "In addition to the linear regression model, let's fine-tune GPT-2 (124M parameters) on the dataset.\n",
    "\n",
    "Since GPT-2 uses subword tokenization, the dataset will be reformatted behind the scenes and divide a word's gaze duration among its subwords. For example, if a word consists of three subwords and has a first-pass gaze duration of 600, the model will be trained to predict 200 for each of those subwords. Refer to the `TransformerGazeTextDataset` in [`gaze_models.py`](modeling/gaze_models.py) for details.\n",
    "\n",
    "> **NOTE:** If you can't or don't want to run the training, the parameters of a trained gaze model have been included in this repository under [`models`](models). You can skip the cell calling `trf_gaze_model.fit()` and instead load it with the subsequent cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8557d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the pretrained model\n",
    "trf_gaze_model = CausalTransformerGazeModel.from_pretrained(\n",
    "    \"openai-community/gpt2\"\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f1a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trf_gaze_model.fit(\n",
    "    train_dataset,\n",
    "    dev_dataset,\n",
    "    batch_size=10,\n",
    "    patience=3,\n",
    "    learning_rate=0.0001,\n",
    ")\n",
    "# Save the trained model\n",
    "torch.save(trf_gaze_model.state_dict(), \"models/trf_gaze_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41dfc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "trf_gaze_model.load_state_dict(torch.load(\"models/trf_gaze_model.pt\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ee3e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_example(trf_gaze_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a9f45",
   "metadata": {},
   "source": [
    "## Evaluating the models\n",
    "\n",
    "First, let's predict the gaze durations on the development set and plot the predictions against the observations for both models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8cc482",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results = lr_gaze_model.evaluate(dev_dataset)\n",
    "plt.scatter(lr_results[\"preds\"], lr_results[\"labels\"])\n",
    "plt.title(\"Linear regression\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Observed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ef277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trf_results = trf_gaze_model.evaluate(dev_dataset)\n",
    "plt.scatter(trf_results[\"preds\"], trf_results[\"labels\"])\n",
    "plt.title(\"Linear regression\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Observed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee543f4",
   "metadata": {},
   "source": [
    "We can also look at some evaluation metrics:\n",
    "\n",
    "- **MAE:** mean absolute error (lower is better)\n",
    "- **RÂ²:** proportion of variance explained (higher is better)\n",
    "- **Pearson:** linear correlation coefficient (higher is better)\n",
    "\n",
    "> **NOTE:** We are not using a separate held-out test set here, since our end goal is not evaluating the gaze models. We are only using these metrics to select the best model for our downstream task (gaze-controlled text generation). If you want to conduct a proper performance evaluation, a separate test set or cross-validation would be more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd0b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linear regression:\")\n",
    "print(f\"MAE: {lr_results[\"mae\"]}\")\n",
    "print(f\"R2: {lr_results[\"r2\"]}\")\n",
    "print(f\"Pearson: {lr_results[\"pearson\"]}\")\n",
    "print()\n",
    "print(\"Transformer:\")\n",
    "print(f\"MAE: {trf_results[\"mae\"]}\")\n",
    "print(f\"R2: {trf_results[\"r2\"]}\")\n",
    "print(f\"Pearson: {trf_results[\"pearson\"]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
